# -*- coding: utf-8 -*-
"""ResNet50.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ueL3SSI6U00aA7x2DArPfxN7JDS_qrdP
"""

import os
import time
import torch
from torch import Tensor
import torch.nn as nn
import torch.nn.functional as F
from torchvision import transforms
from torch.utils.data import DataLoader
from PIL import Image
#from .utils import load_state_dict_from_url
from typing import Type, Any, Callable, Union, List, Optional
from tqdm.notebook import tqdm as tqdm1

try:
    from torch.hub import load_state_dict_from_url
except ImportError:
    from torch.utils.model_zoo import load_url as load_state_dict_from_url

if torch.cuda.is_available(): 
    
    # Tell PyTorch to use the GPU.    
    #device = torch.device("cuda")

    print('There are %d GPU(s) available.' % torch.cuda.device_count())

    print('We will use the GPU:', torch.cuda.get_device_name(0))

model_urls = {
    'resnet18': 'https://download.pytorch.org/models/resnet18-f37072fd.pth',
    'resnet34': 'https://download.pytorch.org/models/resnet34-b627a593.pth',
    'resnet50': 'https://download.pytorch.org/models/resnet50-0676ba61.pth',
    'resnet101': 'https://download.pytorch.org/models/resnet101-63fe2227.pth',
    'resnet152': 'https://download.pytorch.org/models/resnet152-394f9c45.pth',
    'resnext50_32x4d': 'https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth',
    'resnext101_32x8d': 'https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth',
    'wide_resnet50_2': 'https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth',
    'wide_resnet101_2': 'https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth',
}

def conv3x3(
    in_planes: int, 
    out_planes: int, 
    stride: int = 1, 
    groups: int = 1, 
    dilation: int = 1
) -> nn.Conv2d:
    """3x3 convolution with padding"""
    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,
                     padding=dilation, groups=groups, bias=False, dilation=dilation)

def conv1x1(
    in_planes: int, 
    out_planes: int, 
    stride: int = 1
) -> nn.Conv2d:
    """1x1 convolution"""
    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)

class BasicBlock(nn.Module):
    
    expansion: int = 1

    def __init__(
        self,
        inplanes: int,
        planes: int,
        stride: int = 1,
        downsample: Optional[nn.Module] = None,
        groups: int = 1,
        base_width: int = 64,
        dilation: int = 1,
        norm_layer: Optional[Callable[..., nn.Module]] = None
    ) -> None:
        
        super(BasicBlock, self).__init__()
        
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        
        if groups != 1 or base_width != 64:
            raise ValueError('BasicBlock only supports groups=1 and base_width=64')
        
        if dilation > 1:
            raise NotImplementedError("Dilation > 1 not supported in BasicBlock")
        
        # Both self.conv1 and self.downsample layers downsample the input when stride != 1
        self.conv1 = conv3x3(inplanes, planes, stride)
        self.bn1 = norm_layer(planes)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = conv3x3(planes, planes)
        self.bn2 = norm_layer(planes)
        self.downsample = downsample
        self.stride = stride
        
    def forward(self, x: Tensor) -> Tensor:
        
        identity = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)

        if self.downsample is not None:
            identity = self.downsample(x)

        out += identity
        out = self.relu(out)

        return out

class Bottleneck(nn.Module):
    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)
    # while original implementation places the stride at the first 1x1 convolution(self.conv1)
    # according to "Deep residual learning for image recognition"https://arxiv.org/abs/1512.03385.
    # This variant is also known as ResNet V1.5 and improves accuracy according to
    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.
    expansion: int = 4

    def __init__(
        self,
        inplanes: int,
        planes: int,
        stride: int = 1,
        downsample: Optional[nn.Module] = None,
        groups: int = 1,
        base_width: int = 64,
        dilation: int = 1,
        norm_layer: Optional[Callable[..., nn.Module]] = None
    ) -> None:
        
        super(Bottleneck, self).__init__()
        
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        
        width = int(planes * (base_width / 64.)) * groups
        
        # Both self.conv2 and self.downsample layers downsample the input when stride != 1
        self.conv1 = conv1x1(inplanes, width)
        self.bn1 = norm_layer(width)
        self.conv2 = conv3x3(width, width, stride, groups, dilation)
        self.bn2 = norm_layer(width)
        self.conv3 = conv1x1(width, planes * self.expansion)
        self.bn3 = norm_layer(planes * self.expansion)
        self.relu = nn.ReLU(inplace=True)
        self.downsample = downsample
        self.stride = stride
        
    def forward(self, x: Tensor) -> Tensor:
        
        identity = x

        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)

        out = self.conv2(out)
        out = self.bn2(out)
        out = self.relu(out)

        out = self.conv3(out)
        out = self.bn3(out)

        if self.downsample is not None:
            identity = self.downsample(x)

        out += identity
        out = self.relu(out)

        return out

class ResNet(nn.Module):

    def __init__(
        self,
        block: Type[Union[BasicBlock, Bottleneck]],
        layers: List[int],
        num_classes: int = 1000,
        zero_init_residual: bool = False,
        groups: int = 1,
        width_per_group: int = 64,
        replace_stride_with_dilation: Optional[List[bool]] = None,
        norm_layer: Optional[Callable[..., nn.Module]] = None
    ) -> None:
        
        super(ResNet, self).__init__()
        
        if norm_layer is None:
            norm_layer = nn.BatchNorm2d
        
        self._norm_layer = norm_layer

        self.inplanes = 64
        
        self.dilation = 1
        
        if replace_stride_with_dilation is None:
            # each element in the tuple indicates if we should replace
            # the 2x2 stride with a dilated convolution instead
            replace_stride_with_dilation = [False, False, False]
        
        if len(replace_stride_with_dilation) != 3:
            raise ValueError("replace_stride_with_dilation should be None "
                             "or a 3-element tuple, got {}".format(replace_stride_with_dilation))
            
        self.groups = groups
        self.base_width = width_per_group
        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,
                               bias=False)
        self.bn1 = norm_layer(self.inplanes)
        self.relu = nn.ReLU(inplace=True)
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
        self.layer1 = self._make_layer(block, 64, layers[0])
        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,
                                       dilate=replace_stride_with_dilation[0])
        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,
                                       dilate=replace_stride_with_dilation[1])
        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,
                                       dilate=replace_stride_with_dilation[2])
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        self.fc = nn.Linear(512 * block.expansion, num_classes)
        
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)
                
        # Zero-initialize the last BN in each residual branch,
        # so that the residual branch starts with zeros, and each residual block behaves like an identity.
        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677
        if zero_init_residual:
            for m in self.modules():
                if isinstance(m, Bottleneck):
                    nn.init.constant_(m.bn3.weight, 0)  # type: ignore[arg-type]
                elif isinstance(m, BasicBlock):
                    nn.init.constant_(m.bn2.weight, 0)  # type: ignore[arg-type]
                    
    def _make_layer(self, block: Type[Union[BasicBlock, Bottleneck]], planes: int, blocks: int,
                    stride: int = 1, dilate: bool = False) -> nn.Sequential:
        
        norm_layer = self._norm_layer
        downsample = None
        previous_dilation = self.dilation
        
        if dilate:
            self.dilation *= stride
            stride = 1
        if stride != 1 or self.inplanes != planes * block.expansion:
            downsample = nn.Sequential(
                conv1x1(self.inplanes, planes * block.expansion, stride),
                norm_layer(planes * block.expansion),
            )

        layers = []
        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,
                            self.base_width, previous_dilation, norm_layer))
        self.inplanes = planes * block.expansion
        for _ in range(1, blocks):
            layers.append(block(self.inplanes, planes, groups=self.groups,
                                base_width=self.base_width, dilation=self.dilation,
                                norm_layer=norm_layer))

        return nn.Sequential(*layers)
    
    def _forward_impl(self, x: Tensor) -> Tensor:
        # See note [TorchScript super()]
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool(x)

        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)

        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        x = self.fc(x)

        return x
    
    def forward(self, x: Tensor) -> Tensor:
        return self._forward_impl(x)

def _resnet(
    arch: str,
    block: Type[Union[BasicBlock, Bottleneck]],
    layers: List[int],
    pretrained: bool,
    progress: bool,
    **kwargs: Any
) -> ResNet:
    model = ResNet(block, layers, **kwargs)
    if pretrained:
      state_dict = load_state_dict_from_url(model_urls[arch], progress=progress)
      model.load_state_dict(state_dict)
    return model

def resnet50(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> ResNet:
    r"""ResNet-50 model from
    `"Deep Residual Learning for Image Recognition" <https://arxiv.org/pdf/1512.03385.pdf>`_.
    Args:
        pretrained (bool): If True, returns a model pre-trained on ImageNet
        progress (bool): If True, displays a progress bar of the download to stderr
    """
    return _resnet('resnet50', Bottleneck, [3, 4, 6, 3], pretrained, progress,
                   **kwargs)

# Load files' directory.
def files_dir_loader(file_path):
    files_list = []
    os_file_list = os.listdir(file_path)
    for idx, file in enumerate(os_file_list):
        dirs = file_path + file
        files_list.append(dirs)
    return files_list

path = '/content/drive/MyDrive/Colab Notebooks/Cats_Dogs_Recog/'

train_set_txt = path + 'train_set.txt'
test_set_txt = path + 'test_set.txt'

if not os.path.exists(train_set_txt):

    train_cat_path = path + 'training_set/cats/'
    train_dog_path = path + 'training_set/dogs/'
    

    train_cat_img_list = files_dir_loader(train_cat_path)
    train_dog_img_list = files_dir_loader(train_dog_path)


    with open(train_set_txt, mode = 'w') as outfile:
        for _ in train_cat_img_list:
            outfile.write(_ + '\t' + '0' + '\r')
        for _ in train_dog_img_list:
            outfile.write(_ + '\t' + '1' + '\r')

if not os.path.exists(test_set_txt):
    
    test_cat_path = path + 'test_set/cats/'
    test_dog_path = path + 'test_set/dogs/'
    
    test_cat_img_list = files_dir_loader(test_cat_path)
    test_dog_img_list = files_dir_loader(test_dog_path)
    
    with open(test_set_txt, mode = 'w') as outfile:
        for _ in test_cat_img_list:
            outfile.write(_ + '\t' + '0' + '\r')
        for _ in test_dog_img_list:
            outfile.write(_ + '\t' + '1' + '\r')

class MyDataset(torch.utils.data.Dataset):
    def __init__(self, filepath, datatxt, transform=None, target_transform=None):
        
        imgs = []
        fl = open(filepath + datatxt, 'r')
        
        for line in fl:
            line = line.rstrip()
            words = line.split('\t')
            imgs.append((words[0],int(words[1])))
        
        self.imgs = imgs
        self.filepath = filepath
        self.transform = transform
        self.target_transform = target_transform
 
    def __getitem__(self, index):
        fl, label = self.imgs[index]
        img = Image.open(fl).convert('RGB')
        img = img.resize((224,224),Image.ANTIALIAS)

        if self.transform is not None:
            img = self.transform(img)
        return img, label
 
    def __len__(self):
        return len(self.imgs)

train_data = MyDataset('/content/drive/MyDrive/Colab Notebooks/Cats_Dogs_Recog/', 'train_set.txt', transform=transforms.ToTensor())
test_data = MyDataset('/content/drive/MyDrive/Colab Notebooks/Cats_Dogs_Recog/', 'test_set.txt', transform=transforms.ToTensor())

Batch_size = 64

train_loader = DataLoader(dataset = train_data, batch_size = Batch_size, shuffle = True)
test_loader = DataLoader(dataset = test_data, batch_size = Batch_size, shuffle = True)

print(len(train_data))
print(len(test_data))

batch = next(iter(train_loader))
images, labels = batch
print(images.shape)
print(labels.shape)

print(labels[0])

Model = resnet50(True, True)

for param in Model.parameters():
    param.requires_grad = False

fc = nn.Linear(2048, 2)
nn.init.xavier_normal(fc.weight)
Model.fc = fc

for param in Model.fc.parameters():
            param.requires_grad = True

Model = Model.cuda()

Model = resnet50(False, True)
for param in Model.parameters():
    param.requires_grad = False

fc = nn.Linear(2048, 2)
nn.init.xavier_normal(fc.weight)
Model.fc = fc
model_path = '/content/drive/MyDrive/Colab Notebooks/Cats_Dogs_Recog/BackupModels/BackupModel0.990.pth'
Model.load_state_dict(torch.load(model_path))

import numpy as np
import matplotlib.pyplot as plt
import torchvision

test_correct = 0
Model = Model.cuda()
incorrect_list = []
for batches in tqdm1(test_loader):
  

  images, labels = batches
        
  images = images.cuda()
  labels = labels.cuda()

  with torch.no_grad():
      predictions = Model(images)
            
      test_correct += get_num_correct(predictions, labels)
      test_correct_rate = test_correct/len(test_data)
      
      for i in range(len(predictions)):
        print(predictions[i].argmax(),labels[i])
        if predictions[i].argmax() != labels[i]:
          print('--------------------------------------------------------------------')
          incorrect_list.append(images[i])
                
wrong = creat_img_tensor(len(incorrect_list),3,224,224,incorrect_list)
print(test_correct)                        
print("Testing set's correct rate: {}.".format(test_correct_rate))

wrong = wrong.cpu()
    
grid = torchvision.utils.make_grid(wrong, nrow=10)
plt.figure(figsize = (20,20))
plt.imshow(np.transpose(grid, (1,2,0)))

import torchvision

print(wrong)
    
grid = torchvision.utils.make_grid(wrong, nrow=10)
plt.figure(figsize = (12,12))
plt.imshow(np.transpose(grid, (1,2,0)))

def get_num_correct(pred, true):
  n = pred.argmax(dim=1).eq(true).sum().item()
  return n

def creat_img_tensor(count, channels, height, width, img_list):
    img_tensors = torch.empty(count, channels, height, width)

    for idx, img in enumerate(img_list):
        img_tensors[idx,:,:,:] = img
    return img_tensors

num_epochs = 20

learning_rate = 5e-4

optimizer = torch.optim.Adam(Model.parameters(),lr = learning_rate)

Model.train()

time_start = time.time()

print("【-------------------------------Begin Training-------------------------------】")

for epoch in range(num_epochs):
    
    total_loss = 0
    total_correct = 0
    test_correct = 0
    
    good_correct_rate = 0.90
    
    print("epoch {}:".format(epoch + 1))
    
    for batches in tqdm1(train_loader):
        
        images, labels = batches
        
        images = images.cuda()
        labels = labels.cuda()
        predictions = Model(images)
        
        loss = F.cross_entropy(predictions, labels)
        
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        total_loss += loss.item()
        total_correct += get_num_correct(predictions, labels)
        correct_rate = total_correct/len(train_data)
        
    print("Training set's correct rate: {}, loss: {}.\n".format(correct_rate, total_loss))
    
    for batches in tqdm1(test_loader):
        incorrect_list = []

        fl, images, labels = batches
        
        images = images.cuda()
        labels = labels.cuda()

        with torch.no_grad():
            Model.eval()
            predictions = Model(images)
            
            test_correct += get_num_correct(predictions, labels)
            test_correct_rate = test_correct/len(test_data)
            for i in range(len(predictions)):
              if prediction[i].argmax() != labels[i]:
                incorrect_list.append(images[i])
                
    wrong = creat_img_tensor(len(incorrect_list),3,224,224,incorrect_list)
                        
    print("Testing set's correct rate: {}.".format(test_correct_rate))
    
    grid = torchvision.utils.make_grid(wrong, nrow=10)
    plt.figure(figsize = (12,12))
    plt.imshow(np.transpose(grid, (1,2,0)))

    '''
    if test_correct_rate > good_correct_rate:
        good_correct_rate = test_correct_rate
        torch.save(Model.state_dict(), f'/content/drive/My Drive/BackupModels/BackupModel{good_correct_rate:.3f}.pth', _use_new_zipfile_serialization=False)
    '''   
    print("-------------------------------------------------------------------")
    
    
time_end = time.time()

print("My ResNet-50 costs {:.4f} seconds in all.".format(time_end-time_start))